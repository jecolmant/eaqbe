---
sidebar_position: 2
---
# Techniques Supervisées vs Non Supervisées

Nous retrouvons deux types techniques d'apprentissages en machine learning :

<ul>
  <li>L'apprentissage supervisé</li>
  <li>L'apprentissage non supervisé</li>
</ul>

Rappelons tout d'abord quelques notions de bases en apprentissage automatique vu au chapitre précédent [The Universe of Data](/Academy/Data_Sciences/The_Universe_Of_Data). Il est important de bien comprendre la différence entre une technique statistique utilisée dans l'élaboration d'un algorithme pour créer un modèle.

:::tip
Rappel : Une technique est une approche existante en statistique, comme par exemple, une régression linéaire, une régression logistique ou la segmentation automatique (clustering). Un algorithme est l'ensemble de la procédure appliquée pour arriver à un modèle final qui réalisera des tâches automatique. L'algorithme  correspond donc au développement de l'apprentissage d'un modèle.
:::

Chaque type d'apprentissage comprend un ensemble de techniques issues de la statistique et, selon le type de données qui seront fournies lors de la création de l'algorithme et l'objectif du projet data, certaines techniques seront sélectionnées. Il est important de noter que dans de nombreux cas, plusieurs techniques seront utilisées pour créer des modèles qui seront évaluées et sélectionnés. Pour réaliser un modèle, l'algorithme contiendra souvent des itérations avec différents cas ou architecture afin de sélectionner au final le modèle le plus efficient.

Toutes ces techniques, implémentées par la création d'algorithmes qui permettront d'obtenir un modèle peuvent être classées selon deux types d'apprentissage.

## Apprentissage supervisé

L'apprentissage supervisé consiste à créer un modèle de prédiction. C'est-à-dire que sur base de x - des variables explicatives ou plus communément appelées des prédicteurs (soit une ou plusieurs colonnes d'une table) -, le modèle prédira les valeurs de la variable y - variable à expliquer, variable cible ou variable prédite (soit une colonne d'une table). La particularité de l'apprentissage supervisé c'est que l'on dispose de données (enregistrements) qui sont dit "étiquettés", c'est à dire que pour des valeurs de colonnes X (X<sub>1</sub>, X<sub>2</sub>,X<sub>3</sub>,...), on connait les valeurs de la colonne Y correspondante. Le modèle pour alors utiliser ces informations pour apprendre une règle.

Cette règle peut être :

<ul>
<li>
Paramétrique : c'est à dire que la relation entre les valeurs des colonnes X (X<sub>1</sub>, X<sub>2</sub>,X<sub>3</sub>,...) et les valeurs de la colonne Y est définie par un paramètre. Exemple : le prix d'une maison sur base du m². Dans un même quartier et pour des maisons présentant un ensemble de caractéristiques similaires, la superficie en m² a un impact de x % sur le prix final. L'algorithme va analyser les informations à sa disposition  (valeurs des X et valeurs des Y connues) et calculer l'impact de la superficie sur le prix de telle sorte qu'on obtiendra un modèle précis et pour toute nouvelle information concernant les x, il prédira une valeur Y qui sera au plus proche de la valeur finale réelle. 
</li>
<li>
Non-paramétrique : il n'existe pas de paramètres permettant d'expliquer l'impact des valeurs des colonnes X (X<sub>1</sub>, X<sub>2</sub>,X<sub>3</sub>,...) sur les valeurs de la colonne Y ; toutefois l'algorithme est capable, au regard des données dont il dispose de pouvoir prédire les valeurs des y sur base de valeurs des X. Par exemple, une banque souhaite développer un système pour détecter les transactions bancaires frauduleuses. Elle dispose d'un historique de transactions avec des caractéristiques telles que le montant, le lieu, l'heure,.. ainsi que l'indication si la transaction était frauduleuse ou non. Pour une nouvelle transaction, elle souhaiterait prédire si elle est frauduleuse ou non. Dans ce cas, il n'y a pas de paramètre permettant de définir un lien de causalité entre le montant du virement et le fait que la transaction soit faudruleuse ou non. Toutefois, en identifiant des similarités entre les valeurs connues des X (X<sub>1</sub>, X<sub>2</sub>,X<sub>3</sub>,...) pour des transactions frauduleuses et de nouvelles valeurs de X pour une nouvelle transaction, le modèle permettra de mettre en avant le risque que cette transaction est frauduleuse ou non.
</li>
</ul> 

Les techniques issues de la statistique et utilisées dans le cadre d'un apprentissage supervisé peuvent donc être classées en deux catégories : les techniques paramétriques et les techniques non paramétriques. Il n'est pas toujours aisé d'identifier à l'avance quelle technique est plus adaptée. C'est la raison pour laquelle plusieurs modèles seront évalués et l'algorithme permettant d'obtenir ces modèles intégrera plusieurs architecture.

<div className="pmargin">
  <div className="indentp">
    <em>
     Exemple : En tant que concessionnaire, j'aimerais estimer le prix de revente d'un véhicule d'un client dans le cadre d'une reprise. Je dispose d'informations sur le véhicule (kilométrage, puissance moteur, nombre de portes,... = X<sub>1</sub>, X<sub>2</sub>,X<sub>3</sub>,...) ainsi que l'historique d'autres véhicules et leur prix de vente finale. Je ne peux prédire à l'avance si l'application d'une technique paramétrique me permettra d'obtenir un meilleur modèle (meilleures prédictions) qu'une technique non paramétrique. Je vais donc préparer mes données et appliquer une technique paramétrique (par exemple une régression) et une technique non paramétrique (par exemple K-Nearest Neighbors). Au sein même de la technique paramétrique (régression), nous ne savons pas déterminer si une régression linéaire apportera un meilleur résultat qu'une régression polynomiale. Par conséquent, nous évaluerons les deux cas.

    </em>
  </div>
</div>


 ### L'estimation

Les techniques de prédiction d'estimation cherchent à estimer une variable cible Y numérique (continue) sur base d’autres variables X (X<sub>1</sub>, X<sub>2</sub>,X<sub>3</sub>,...) également appelées prédicteurs


<div className="pmargin">
  <div className="indentp">
    <em>
    Une agence immobilière souhaiterait prédire le prix de vente des nouvelles maisons dont ils ont la charge d'assurer la vente afin de négocier au mieux avec leur client les honoraires qu'ils pourront retirer de la vente. Pour chaque maison, ils encodent de nombreuses informations (Superficie en m² [ colonne 1 ], Nbre de chambres [ colonne 2 ] , Consommation énergétique [ Colonne 3 ] et  Nbre de salles de bain [ Colonne 4 ]). L'agence dispose de données historiques avec toutes les informations sur les anciennes ventes, dont le prix de vente finale [ Colonne 5 ]. 

    | ClientID <br /> | Superficie m²  X<sub>1</sub> <br />| Chambres X<sub>2</sub><br />  | PEB kWh/m²/an  X<sub>3</sub> <br />| Salles de bain  X<sub>4</sub> <br />| Prix <br /> Y |
    |:-----------:|:------------:|:-------------:|:--------------:|:--------------:|:----------------:|
    | 98 | 252 | 5 | 345| 4 | 652,945€ |
    | 97 | 232 | 3 | 304| 1 | 535,975€ |
    | ... | ... | ...| ...| ... | ...|

    Dans cet exemple, les prédicteurs (variables explicatives) seraient les colonnes  X<sub>1</sub>, X<sub>2</sub>,  X<sub>3</sub> et X<sub>4</sub> et la variable à prédire (variable à expliquer) serait la colonne Y.

    Si un nouveau client met en vente sa maison  avec les données suivantes 99	245	4	325 2	 ; le modèle pourrait définir que le montant de vente sera de 595,000 € ;  Il est important de noter que la prédiction ne sera jamais parfaite, mais le rôle du data scientist est de construire un modèle qui va minimiser les erreurs entre la valeur prédite et la valeur réelle
    </em>
  </div>
</div>

Nous retrouvons parmi les techniques supervisées d'estimation les plus utilisées : 

<ul>
  <li>Les régressions (linéaire, polynomiales)</li>
  <li>Les réseaux de neurones (MLP, CNN, RNN, LSTM, GRU)</li>
  <li>Les arbres de régression (+Forêts aléatoires, Xboost)</li>
  <li>Le K-Nearest Neighbors</li>
  <li>...</li>
</ul> 

### Le classement

Dans le cadre d'un classement, Les techniques de prédiction cherchent à prédire une variable cible Y catégorique sur base d’autres variables X (X<sub>1</sub>, X<sub>2</sub>,X<sub>3</sub>,...) également appelées prédicteurs. Le classement peut être binaire, c'est à dire qu'il permet d'obtenir comme valeurs dans la colonne Y (1) ou (0) ou il peut s'agir d'un classement pour plusieurs valeurs ( Y  > 2 valeurs comme par exemple "bon", "moyen","mauvais")

Le modèle renverra une valeur entre (0) et (1), et le data scientist doit définir un seuil (en général < 0.5 = (0) et >= 0.5 = (1)). La valeur correspond en réalité à une probabilité, c'est à dire la probabilité que l'enregistrement soit = à (1).


<div className="pmargin">
  <div className="indentp">
    <em>
    Un hopital souhaite mettre en place un algorithme pour évaluer lorsqu'un patient arrive aux urgences si il est contagieux ou non. Dès son arrivée, chaque patient est pris en charge par une infirmière et ses paramètres vitaux sont enregistrés et encodés dans un ordinateur (Température corporelle [ colonne 1 ], pulsations cardiaques [ colonne 2 ] , tension artérielle [ Colonne 3 ], masse musculaire [ Colonne 4 ]). L'hôpital dispose de données historiques avec toutes les informations des paramètres et les informations sur l'état du patient, c'est à dire est-ce qu'il est contagieux ou non [ Colonne 5 ]. Dans cet exemple, vous allez identifier les variables (les colonnes de la table) qui contiennent les données utiles pour votre apprentissage en tant que prédicteurs afin déterminer si un patient est contagieux (1) ou non contagieux (0).

    | PatientID | Température corporelle  <br /> X<sub>1</sub> | Pulsations cardiaques  <br /> X<sub>2</sub> | Tension artérielle <br /> X<sub>3</sub> | Masse musculaire <br /> X<sub>4</sub> | Contagieux  <br /><br /> Y |
    |:---------------------:|:----------:|:---------------------:|:---------------------:|:---------------------:|:---------------------:|
    | 9856 | 39.2 | 145 | 15/9| 75% | 1 |
    | 9857 | 36.7 | 68 | 11/9| 68% | 0 |
    | ... | ... | ...| ...| ... | ...|

    Dans cet exemple, les prédicteurs (variables explicatives) seraient les colonnes  X<sub>1</sub>,  X<sub>2</sub> et X<sub>3</sub> (la colonne  X<sub>4</sub> n'ayant pas d'incidence sur l'état contagieux ou non d'un patient) et la variable à prédire (variable à expliquer) serait la colonne Y.

    Si un nouveau patient se présente avec les données suivantes 9858	38.7	90	13/9	67%	 ; le modèle pourrait définir que la probabilité qu'il soit contagieux est de 0.69 ; 0.69 étant >= 0.5 , le patient sera considéré comme contagieux. Il est important de noter que dans le cadre d'un classement, on va toujours définir l'hypothèse négative comme étant (1) (par exemple contagieux), afin de favoriser le fait de classer des patients non contagieux comme étant contagieux plutôt que des patients contagieux comme étant non contagieux.
    </em>
  </div>
</div>

Nous retrouvons parmi les techniques supervisées d'estimation les plus utilisées : 
<ul>
  <li>La régression logistique</li>
  <li>L'analyse discrimante linéaire et quadratique</li>
  <li>Les réseaux de neurones (MLP, CNN, RNN, LSTM, GRU)</li>
  <li>Les arbres de régression (+Forêts aléatoires, Xboost)</li>
  <li>Le K-Nearest Neighbors</li>
  <li>...</li>
</ul> 


:bulb: **Important :** Nous avons vu qu'en sciences des données il existe deux types de prédictions pour l'apprentissage supervisé : l'estimation et le classement. Il est important de noter que certaines techniques issues de la statistique peuvent être utilisées pour l'estimation et le classement ; d'autres techniques sont spécifiques soit à l'estimation soit au classement.

## L'apprentissage non supervisé

Les méthodes non supervisées permettent de comprendre et décrire des données afin de révéler des tendances sous-jacentes. Les techniques supervisées diffèrent des techniques supervisées dans le sens où 1) il n'y a pas de valeur cible à prédire - nous utilisons toutes les colonnes comme étant des X et 2) Il n'y a pas de phase d'apprentissage comme nous l'aborderons au prochain chapitre. Toutes les données sont utilisées

Les modèles non supervisés sont également populaires et utilisés pour de nombreuses applications :

<ul>
  <li>La segmentation (clustering) : identifier des enregistrements qui sont similaires à d'autres enregistrements et forment ensemble un groupe différent des autres groupes (exemple mieux segmenter la clientèle cible)</li>
  <li>Les règles d'association : identifier des combinaisons de produits souvent achetés ensemble et pouvoir mettre des actions en place à cet égard</li>
  <li>Le filtrage collaboratif (considéré comme non supervisés car il ne fait pas appel à une phase d'apprentissage sur un sous-ensemble des données mais comprends une étape d'une technique supervisées) : si j'ai regardé le film A et que je l'ai aimé, une autre personne a aimé le film A et a des caractéristiques similaires à ma personne. Cette personne a aimé le film B donc je vais probablement aimer le film B</li>
  <li>L'analyse en composantes principales : transformer l'espace des données dont certaines sont correlées en un nouvel espace de moindre dimensions et décorrelées</li>
  <li>La détection d'anomalies : découvrir des enregistrements anormaux</li>
</ul>

