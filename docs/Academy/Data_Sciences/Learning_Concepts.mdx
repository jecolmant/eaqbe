---
sidebar_position: 3
---
# Notions d'apprentissage

Nous avons vu au chapitre pr√©c√©dent [Techniques Supervis√©es vs Non Supervis√©es](/Academy/Data_Sciences/Supervised_&_Unsupervised), que nous parlons d'apprentissage pour les techniques supervis√©es et non-supervis√©es.

Toutefois, la litt√©rature se r√©f√®re davantage aux techniques supervis√©es pour √©voquer les principes d'apprentissage. Cela a une certaine logique √©tant donn√© que dans le cadre de l'application d'une technique supervis√©e, nous, en tant que data scientist, jouons le r√¥le de professeur de la machine et dans cette d√©marche, nous l'entrainnons et nous v√©rifions si la machine a bien appris et si elle fait correctement son travail. A contrario, les techniques non-supervis√©es ne sont pas explicitement guid√©es dans l'apprentissage qui est enti√®rement autonome √† la machine et dont la finalit√© sera de mettre en avant des tendances ou des relations cach√©es que nous en tant que data scientist devront interpr√©ter comme √©tant utile ou non.

D'ailleurs un autre √©l√©ment fondamental qui distincte un apprentissage supervis√© d'un apprentissage non-supervis√© est le fait que la machine, dans un apprentissage supervis√©, assurera une continuit√© de cet apprentissage de mani√®re autonome par la suite. Nous avons vu comme exemple que si nous apprenons √† une machine que lorsqu'un email contient les mots "gratuit", "lotterie" et "argent", il y a une forte probabilit√© que ce soit un spam (courrier non d√©sirable), la machine pourrait d√©couvrir par la suite que le mot "bitcoin" est souvent reprit √©galement avec ces mots et donc sans que nous l'ayons explicitement programm√©e, elle int√©grera une nouvelle r√®gle : celle d'identifier le mot "bitcoin" comme ayant une certaine probabilit√© √† √™tre un spam. Dans le cadre d'un apprentissage non-supervis√©, √† chaque fois que l'on applique l'algorithme sur des nouvelles donn√©es, on obtiendra un nouveau mod√®le, c'est √† dire que la machine recommencera son apprentissage √† z√©ro.

## D√©roulement d'un apprentissage supervis√©

Pour r√©aliser un mod√®le de pr√©diction, nous devons disposer de donn√©es qui comprennent les valeurs que l‚Äôon souhaite pr√©dire. On parle de donn√©es ¬´¬†√©tiquet√©es¬†¬ª (labeled data). Nous devons donc disposer de colonnes consid√©r√©es comme √©tant des variables explicatives (des pr√©dicteurs, les X  : X<sub>1</sub>, X<sub>2</sub>,X<sub>3</sub>,...) ainsi qu'une variable √† expliquer (la variable pr√©dite Y).

### R√©partition d'un dataframe en variables explicatives et variable cible

La premi√®re √©tape d'un apprentissage supervis√©s et donc d'identifier et s√©lectionner les X et √©galement identifier la colonne Y. Bien entendu, nous partons de l'hypoth√®se que nous disposons de donn√©es "propres", c'est √† dire que toutes les √©tapes d'analyse et de pr√©paration (notamment des transformations) ont √©t√© r√©alis√©es et les donn√©es sont structur√©es et donc repr√©sent√©es sous forme tabulaire. Nous partons √©galement du postulat que la s√©lection des pr√©dicteurs - variables explicatives les plus utiles pour cr√©er notre mod√®le - a d√©j√† √©t√© r√©alis√© √©galement.

Nous disposons d'une table contenant des colonnes X et une colonne Y, comme suit :

    | X<sub>1</sub> | X<sub>2</sub> | X<sub>3</sub> | X<sub>...</sub> | X<sub>n</sub> |  Y |
    |:---------------------:|:----------:|:---------------------:|:---------------------:|:---------------------:|:------------------------:|
    | X<sub>1,1</sub> | X<sub>1,2</sub> | X<sub>1,3</sub>| ...| X<sub>1,n</sub> | Y<sub>1</sub>|
    | X<sub>2,1</sub> | X<sub>2,2</sub> | X<sub>2,3</sub>| ...| X<sub>n,n</sub> | Y<sub>2</sub>|
    | ... | ... | ...| ...| ... | ...|
    | X<sub>n,1</sub> | X<sub>n,2</sub> | X<sub>n,3</sub>| ...| X<sub>n,n</sub>| Y<sub>3</sub>|


import MyCustomTip from '@site/src/components/HomepageFeatures/MyCustomTip';

<MyCustomTip>
  X<sub>2,3</sub> correspond √† la valeur de la 2e ligne de la 3e colonne
</MyCustomTip>

Pour convertir nos donn√©es en X et Y, il suffit simplement de donner l'instruction des colonnes appartenant √† X et celle appartenant √† Y. L'√©criture [['En-t√™te Colonne 1','En-t√™te Colonne 2' ]] signifie qu'il y a plusieurs colonnes, alors que [ ] signifie qu'il n'y a qu'une seule colonne.

```python
import pandas as pd

df = pd.DataFrame(data)


X = df[['X1', 'X2', 'X3']]  
y = df['Y']
```

### Partitionnement des donn√©es

La seconde √©tape consiste √† subdiviser (partitionner) les enregistrements afin d'utiliser une partition pour cr√©er le mod√®le (apprendre √† la machine) et l'autre partition pour valider le mod√®le (v√©rifier que l'√©l√®ve, la machine, a bien appris).

On partitionne donc les enregistrements des colonnes X et Y en deux parties :

<ul>
  <li>Set d'entrainnement qui comprends les donn√©es d'apprentissage</li>
  <li>Set de validation qui comprends les donn√©es qui seront utilis√©es pour v√©rifier l'apprentissage</li>
</ul> 

Le partitionnement des donn√©es (al√©atoire) d√©pend fortement de la quantit√© de donn√©es √† dispositon et de la complexit√© de la technique qui sera utilis√©. Par exemple, si on dispose d'un nombre de donn√©es restreint, le partitionnement sera r√©alis√© comme suit : Set d'entrainnement 60 % ; Set de test 40 %.

Par contre, si on dispose de nombreuse donn√©es et que la technique requi√®re un nombre important d'enregistrements (par exemple un r√©seau de neurones), le partitionnement sera r√©alis√© comme suit : Set d'entrainnement 80 % ; Set de test 20 %.

> :bulb: **Tip:** La r√©partition des enregistrements entre la partition "entrainnement" et la partition "validation" doit √™tre r√©alis√©e de mani√®re al√©atoire 

Ce partitionnement peut √™tre r√©alis√© de mani√®re simple √† l'aide de la librairie sp√©cialis√©e en machine learning : sickit-learn :

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

X et y reprennent toutes nos donn√©es. X contient plusieurs colonnes et de nombreux enregistrements. Y ne contient qu'une colonne et le m√™me nombre d'enregistrements que X. La fonction train_test_split va nous permettre de r√©aliser ce partionnement et comprends ci-dessus 4 arguments. Le premier identifie les X, le second identifie y, le troisi√®me d√©finit la taille de la partition de test (dans ce cas-ci 20 %) et le quatri√®me, random_state permet de fixer le graine de g√©n√©rateur de nombre al√©atoire √† 42, de sorte qu'√† chaquefois que nous ex√©cutons la fonction train_test_split avec la m√™me valeur pour random_state, nous obtiendrons exactement la m√™me division de donn√©es. 

### √âtape d'apprentissage 

Dans la phase d'apprentissage, nous appliquons une technique statistique √† nos donn√©es d'entrainnement. Par exemple, pour la r√©gression lin√©aire, technique supervis√©e param√©trique, l'algorithme va r√©aliser un processus comprenant diff√©rentes √©tapes permettant de d√©finir les param√®tres, c'est √† dire les incidences des valeurs de X sur la valeur Y. Par exemple : l'incidence de la superficie en m¬≤ d'une maison sur sa valeur.

L'algorithme - qui consiste en une s√©rie d'√©tapes (y compris l'√©tape de partitionnement des donn√©es) - , va nous fournir un mod√®le que nous allons pouvoir appliquer √† de nouvelles donn√©es.

Voici un exemple d'apprentissage en appliquant un model de r√©gression lin√©aire pr√©d√©fini (Nous d√©composerons ce mod√®le dans le chapitre sur la r√©gression lin√©aire).

```python
model = LinearRegression()
model.fit(X_train, y_train)
```

### √âtape de validation

D√®s que nous obtenons un mod√®le, nous allons le v√©rifier, c'est √† dire le valider. La mani√®re la plus simple de r√©aliser une premi√®re validation est de v√©rifier si le mod√®le fonctionne correctement en lui appliquant les donn√©es sur base desquelles il a r√©alis√© son apprentissage, mais cette fois-ci, on va lui cacher les valeurs des y et lui demander de les pr√©dire. √©tant donn√© que nous utilisons les m√™mes donn√©es que celle utilis√©es lors de l'apprentissage, nous nous attendons √† obtenir √† cette √©tape-ci, un excellent score en v√©rifiant les valeurs pr√©dites par rapport aux valeurs r√©elles. L'id√©e est de s'assurer que ce mod√®le est robuste dans son apprentissage.

```python
y_pred = model.predict(X_train)
```

Nous utilisons la fonction de pr√©diction de notre mod√®le sur les m√™mes valeurs de X √† partir desquelles notre mod√®le a √©t√© cr√©√©.

Les erreurs de pr√©diction dans le set d‚Äôentrainement (validation) nous donnent une indication sur l‚Äôajustement du mod√®le (sous-entra√Æn√© ou surentrain√©). 


:::warning
L'erreur dans l'√©tape de validation, c'es √† dire la diff√©rence entre les valeurs pr√©dites et valeurs r√©elles doit √™tre minimale mais ne doit absolument pas correspondre √† 0. Si vous obtenez 0, c'est que votre mod√®le est en sur-apprentissage. Il connait trop bien ses donn√©es d'entrainnement et ne sera probablement pas g√©n√©ralisable et donc donnera un score m√©diocre sur de nouvelles donn√©es (par exemple lors de l'√©tape de test)
:::



### √âtape de test

Si l'√©tape de validation est concluante, c'est √† dire que nous obtenons une fiabilit√© √©lev√©e (faible diff√©rence entre les valeurs pr√©dites par le mod√®le et les valeurs r√©elles connues), nous passons √† la phase de test. Attention, si l'√©tape de validation m√®ne √† une fiabilit√© faible, cela signifie que le mod√®le est sous-entrainn√©. Il n'est pas capable de pr√©dire correctement des valeurs sur lesquelles il a √©t√© entrainn√© ! Il ne dispose pas de suffisamment d'enregistrements ou de colonnes et d'enregistrements. 

L'√©tape de test consiste √† appliquer notre mod√®le sur la seconde partition de nos donn√©es, celles √† partir desquelles notre mod√®le n'a pas √©t√© entrainn√© mais dont nous connaissons les valeurs des X et les valeurs des Y. Nous appliquons la fonction de pr√©diction sur les X et nous comparons les valeurs obtenues.



```python
y_pred = model.predict(X_test)
```
Nous v√©rifions ensuite la diff√©rence entre les valeurs pr√©dites et les valeurs r√©elles.

Le r√©sultat de l'√©tape de test devrait √™tre l√©g√®rement inf√©rieur √† l'√©tape de validation signifiant que notre mod√®le est capable de d√©finir une r√®gle g√©n√©ralisable. Sur base des donn√©es d'entrainnement il a √©t√© capable de g√©n√©raliser la r√®gle √† n'importe quelle donn√©es.


## √âvaluation d'un apprentissage supervis√©

Comment nous l'avions mentionn√© pr√©c√©demment, nous serons confront√© √† la n√©cessit√© d'√©valuer plusieurs techniques par exemple pour une estimation, une r√©gression, un arbre de r√©gr√©ssion ou les K-Nearest Neighbors ainsi que diff√©rentes configuration des mod√®les. Par exemple, pour une r√©gression, il s'agirait d'√©valuer un mod√®le lin√©aire et un mod√®le polynomial afin d'identifier lequel est le plus performant. 

Les erreurs de pr√©diction dans le set d‚Äôentrainement (validation) nous donnent une indication sur l‚Äôajustement du mod√®le (sous-entra√Æn√© ou surentrain√©). Par exemple, si l‚Äôerreur d‚Äôentrainement est de 0, mon mod√®le est certainement en sur-apprentissage.Les erreurs de pr√©diction dans le set de test (erreurs pr√©dictives) mesurent la capacit√© de pr√©diction du mod√®le.Les erreurs dans le set validation doivent √™tre inf√©rieures aux erreurs dans le set de validation √©tant donn√© que le mod√®le a √©t√© entrain√© sur base du set d‚Äôentrainement (et donc du set de validation). 

Un erreur est en r√©alit√© la diff√©rence entre la valeur r√©elle de Y et connue et la valeur pr√©dite par le mod√®le que l'on nomme ≈∑

e = y-≈∑  On notera e<sub>i</sub> = (ùë¶<sub>i</sub> ‚àí ≈∑¬†<sub>i</sub> ) pour l'erreur d'un enregistrement sp√©cifique et la litt√©rature privil√©gie l'utilisation de l'erreur quadratique moyenne (root mean square error) qui donne plus de poids aux erreurs importantes et se note 

The quadratic formula is: 

Here's an inline equation: $e_i = (y_i - \hat{y}_i)$

And a block equation:

$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

### √âvaluation d'un mod√®le d'estimation

### √âvaluation d'un mod√®le de classement

### R√®gle g√©n√©ralisable